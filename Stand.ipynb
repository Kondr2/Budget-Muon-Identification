{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "import scoring\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "import subprocess\n",
    "import lightgbm as lgb\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/data/kondratov/data\"\n",
    "SAVED_MODELS_PATH = \"/data/kondratov/models\"\n",
    "RANDSEED = None\n",
    "# Constant if models are not trained\n",
    "TRAIN = False\n",
    "# Constant if required to save models\n",
    "SAVE = True\n",
    "\n",
    "# Data features\n",
    "SIMPLE_FEATURE_COLUMNS = ['ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]', 'avg_cs[1]',\n",
    "    'avg_cs[2]', 'avg_cs[3]', 'MatchedHit_TYPE[0]', 'MatchedHit_TYPE[1]',\n",
    "    'MatchedHit_TYPE[2]', 'MatchedHit_TYPE[3]', 'MatchedHit_X[0]',\n",
    "    'MatchedHit_X[1]', 'MatchedHit_X[2]', 'MatchedHit_X[3]',\n",
    "    'MatchedHit_Y[0]', 'MatchedHit_Y[1]', 'MatchedHit_Y[2]',\n",
    "    'MatchedHit_Y[3]', 'MatchedHit_Z[0]', 'MatchedHit_Z[1]',\n",
    "    'MatchedHit_Z[2]', 'MatchedHit_Z[3]', 'MatchedHit_T[0]',\n",
    "    'MatchedHit_T[1]', 'MatchedHit_T[2]', 'MatchedHit_T[3]',\n",
    "    'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
    "    'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
    "    'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
    "    'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
    "    'MatchedHit_DT[0]', 'MatchedHit_DT[1]', 'MatchedHit_DT[2]',\n",
    "    'MatchedHit_DT[3]', 'Lextra_X[0]', 'Lextra_X[1]', 'Lextra_X[2]',\n",
    "    'Lextra_X[3]', 'Lextra_Y[0]', 'Lextra_Y[1]', 'Lextra_Y[2]',\n",
    "    'Lextra_Y[3]', 'Mextra_DY2[0]', 'Mextra_DY2[1]', 'Mextra_DY2[2]',\n",
    "    'Mextra_DY2[3]', 'Mextra_DX2[0]', 'Mextra_DX2[1]', 'Mextra_DX2[2]',\n",
    "    'Mextra_DX2[3]', 'P', 'PT', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveClassifierLoss(object):\n",
    "    def __init__(self, prob_first_clf, prob_full):\n",
    "        self.prob_first_clf = prob_first_clf\n",
    "        self.count = len(prob_first_clf)\n",
    "        self.prob_full = prob_full\n",
    "        self.q = np.zeros(self.count)\n",
    "        self.last_gate = np.zeros(self.count)\n",
    "        self.last_clf = np.zeros(self.count)\n",
    "    def loss_clf(self, preds, train_data):\n",
    "        labels = train_data.get_label() * 2 - 1\n",
    "        exp_clf = np.exp(-labels * preds)\n",
    "        exp_sum = 1 + exp_clf\n",
    "        grad = -(1 - self.q) * labels * exp_clf / exp_sum\n",
    "        hess = (1 - self.q) * exp_clf / exp_sum / exp_sum\n",
    "        return grad, hess\n",
    "    def loss_gate(self, preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        exp_gate = np.exp(-preds)\n",
    "        exp_sum = 1 + exp_gate\n",
    "        grad = (1 - self.q) / exp_sum - self.q * exp_gate / exp_sum\n",
    "        hess = exp_gate / exp_sum / exp_sum\n",
    "        return grad, hess\n",
    "    def set_score_clf(self, score):\n",
    "        self.last_clf = score\n",
    "    def set_score_gate(self, score):\n",
    "        self.last_gate = score\n",
    "    def update(self, labels, score_second_clf, score_gate):\n",
    "        self.last_gate = np.zeros(self.count)\n",
    "        self.last_clf = np.zeros(self.count)\n",
    "        exp_b = -np.log(self.prob_first_clf) + np.log(1 + np.exp(-score_gate))\n",
    "        exp_a = -np.log(1 + np.exp(-labels * score_second_clf)) + np.log(1 + np.exp(score_gate))\n",
    "        min_beta = 0.0001\n",
    "        max_beta = 100000\n",
    "        diff = 0.0001\n",
    "        exp_g = 1. / (1 + np.exp(score_gate))\n",
    "        exp_s = 1. / (1 + np.exp(labels * score_second_clf))\n",
    "        exp_first = self.prob_first_clf * exp_g\n",
    "        exp_second = (1 - exp_g) * exp_s\n",
    "        while max_beta - min_beta > diff:\n",
    "            beta = (max_beta + min_beta) / 2\n",
    "            q_sum = np.sum(exp_first / (exp_first + exp_second * beta)) / self.count\n",
    "            if q_sum < self.prob_full:\n",
    "                max_beta = beta\n",
    "            else:\n",
    "                min_beta = beta\n",
    "        self.q = exp_first / (exp_first + exp_second * beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedClassifier(object):\n",
    "    def __init__(self, param_first, param_second, prob_full=0.7,\n",
    "                 first_clf=None, second_clf=None, gate_clf=None):\n",
    "        self.param_first = param_first\n",
    "        self.param_second = param_second\n",
    "        self.prob_full = prob_full\n",
    "        self.first_clf = None\n",
    "        self.second_clf = None\n",
    "        self.gate_clf = None\n",
    "        if first_clf is not None:\n",
    "            self.first_clf = first_clf\n",
    "        if  second_clf is not None and gate_clf is not None:\n",
    "            self.second_clf = second_clf\n",
    "            self.gate_clf = gate_clf\n",
    "    def train(self, data):\n",
    "        transformed_data = lgb.Dataset(data.loc[:, SIMPLE_FEATURE_COLUMNS],\n",
    "                                       data.label,\n",
    "                                       weight=data.weight,\n",
    "                                       free_raw_data=False)\n",
    "        if self.first_clf is None:\n",
    "            self.first_clf = lgb.train(self.param_first, transformed_data, feature_name=SIMPLE_FEATURE_COLUMNS,\n",
    "                                       num_boost_round=self.param_first['num_iterations'])\n",
    "        self.second_clf = lgb.Booster(self.param_second, transformed_data)\n",
    "        self.gate_clf = lgb.Booster(self.param_second, transformed_data)\n",
    "        max_iter = 5\n",
    "        prob_first_clf = self.first_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values)\n",
    "        loss = AdaptiveClassifierLoss(prob_first_clf, self.prob_full)\n",
    "        for it in range(max_iter):\n",
    "            score_second_clf = self.second_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "            score_gate_clf = self.gate_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "            loss.update(data.label.values, score_second_clf, score_gate_clf)\n",
    "            self.second_clf = lgb.Booster(self.param_second, transformed_data)\n",
    "            self.gate_clf = lgb.Booster(self.param_second, transformed_data)\n",
    "            for tree in range(self.param_second['num_iterations']):\n",
    "                self.second_clf.update(fobj=loss.loss_clf)\n",
    "                self.gate_clf.update(fobj=loss.loss_gate)\n",
    "                score_second_clf = self.second_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "                score_gate_clf = self.gate_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "                loss.set_score_clf(score_second_clf)\n",
    "                loss.set_score_gate(score_gate_clf)\n",
    "        self.q = loss.q\n",
    "            \n",
    "    def predict(self, data):\n",
    "        gate = self.gate_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values)\n",
    "        first = self.first_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "        second = self.second_clf.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values, raw_score=True)\n",
    "        for it in range(len(first)):\n",
    "            if gate[it] < self.prob_full:\n",
    "                first[it] = second[it]\n",
    "        return first\n",
    "    def predict_timeless(self, data):\n",
    "        # This method works slow on Python, use C++ version or predict() method instead\n",
    "        for _, row in data.iterrows():\n",
    "            gate = self.gate_clf.predict(row.loc[SIMPLE_FEATURE_COLUMNS].values.reshape(1, -1))\n",
    "            if gate > self.prob_full:\n",
    "                pred.append(self.first_clf.predict(row.loc[SIMPLE_FEATURE_COLUMNS].values.reshape(1, -1), raw_score=True))\n",
    "            else:\n",
    "                pred.append(self.second_clf.predict(row.loc[SIMPLE_FEATURE_COLUMNS].values.reshape(1, -1), raw_score=True))\n",
    "        return np.array(pred)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code was written similar to the example from here: https://github.com/catboost/benchmarks/blob/master/shap_speed/speed_comparison.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, parameters={}, boosting=None, model=None):\n",
    "    if boosting == 'Baseline':\n",
    "        model = catboost.CatBoostClassifier(iterations=550, max_depth=8,\n",
    "                                            learning_rate=parameters['learning_rate'],\n",
    "                                            thread_count=16, verbose=False)\n",
    "        model.fit(data.loc[:, SIMPLE_FEATURE_COLUMNS].values,\n",
    "                  data.label.values,\n",
    "                  sample_weight=data.weight.values)\n",
    "    elif boosting == 'CatBoostClassifier':\n",
    "        if model is None:\n",
    "            params = {}\n",
    "            if \"learning_rate\" in parameters:\n",
    "                params[\"learning_rate\"] = parameters[\"learning_rate\"]\n",
    "            if \"max_depth\" in parameters:\n",
    "                params[\"max_depth\"] = parameters[\"max_depth\"]\n",
    "            else:\n",
    "                params[\"max_depth\"] = 8\n",
    "            if \"tree_count\" in parameters:\n",
    "                params[\"iterations\"] = parameters[\"tree_count\"]\n",
    "            else:\n",
    "                params[\"iterations\"] = 550\n",
    "            model = catboost.CatBoostClassifier(thread_count=16, verbose=False, **params)\n",
    "        model.fit(data.loc[:, SIMPLE_FEATURE_COLUMNS].values,\n",
    "              data.label.values,\n",
    "              sample_weight=data.weight.values)\n",
    "    elif boosting == 'CEGB':\n",
    "        params = {\n",
    "            'boosting_type': 'cegb',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'num_leaves': 25,\n",
    "            'max_depth': 8,\n",
    "            'num_iterations': 1000,\n",
    "            'learning_rate': 0.3,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0,\n",
    "        }\n",
    "        if \"learning_rate\" in parameters:\n",
    "            params['learning_rate'] = parameters[\"learning_rate\"]\n",
    "        trees = 100\n",
    "        if \"tree_count\" in parameters:\n",
    "            trees = parameters[\"tree_count\"]\n",
    "            params['num_iterations'] = parameters[\"tree_count\"]\n",
    "        if \"num_leaves\" in parameters:\n",
    "            params['num_leaves'] = parameters[\"num_leaves\"]\n",
    "        if \"max_bin\" in parameters:\n",
    "            params['max_bin'] = parameters[\"max_bin\"]\n",
    "        model = lgb.train(params, data, feature_name=SIMPLE_FEATURE_COLUMNS,\n",
    "                          num_boost_round=trees)\n",
    "    elif boosting == 'AdaptiveCassifier':\n",
    "        params_first = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'num_leaves': 25,\n",
    "            'max_depth': 8,\n",
    "            'num_iterations': 50,\n",
    "            'learning_rate': 0.3,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0,\n",
    "        }\n",
    "        if \"learning_rate\" in parameters['first']:\n",
    "            params_first['learning_rate'] = parameters['first'][\"learning_rate\"]\n",
    "        if \"tree_count\" in parameters['first']:\n",
    "            params_first['num_iterations'] = parameters['first'][\"tree_count\"]\n",
    "        if 'first_clf' in parameters:\n",
    "            first_clf = parameters['first_clf']\n",
    "        else:\n",
    "            first_clf = None\n",
    "        params_second = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'num_leaves': 25,\n",
    "            'max_depth': 5,\n",
    "            'num_iterations': 10,\n",
    "            'learning_rate': 0.9,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0,\n",
    "        }\n",
    "        if \"learning_rate\" in parameters['second']:\n",
    "            params_second['learning_rate'] = parameters['second'][\"learning_rate\"]\n",
    "        if \"tree_count\" in parameters['second']:\n",
    "            params_second['num_iterations'] = parameters['second'][\"tree_count\"]\n",
    "        model = GatedClassifier(params_first, params_second, prob_full=parameters['threshold'])\n",
    "        model.train(data)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, parameters, boosting, model):\n",
    "    if boosting == 'Baseline':\n",
    "        testing = subprocess.Popen(['cpp/catboost_eval',\n",
    "                                    '-model', os.path.join(SAVED_MODELS_PATH, 'baseline.cbm'),\n",
    "                                    '-output', os.path.join(DATA_PATH, 'tmp/model_pred.csv'),\n",
    "                                    '-time', os.path.join(DATA_PATH, 'tmp/time.txt'),\n",
    "                                    '-input', os.path.join(DATA_PATH, 'transformed_test_features.csv')],\n",
    "                                    stdout=subprocess.PIPE)\n",
    "        testing.wait()\n",
    "        file = open(os.path.join(DATA_PATH, 'tmp/time.txt'))\n",
    "        st = file.readline()\n",
    "        time = float(st)\n",
    "        pred = pd.read_csv(os.path.join(DATA_PATH, 'tmp/model_pred.csv'))\n",
    "        accuracy = scoring.rejection90(data.label.values, pred.prediction.values, data.weight.values)\n",
    "    elif boosting == 'CatBoostClassifier':\n",
    "        testing = subprocess.Popen(['cpp/catboost_eval',\n",
    "                                    '-model', os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)),\n",
    "                                    '-output', os.path.join(DATA_PATH, 'tmp/model_pred.csv'),\n",
    "                                    '-time', os.path.join(DATA_PATH, 'tmp/time.txt'),\n",
    "                                    '-input', os.path.join(DATA_PATH, 'transformed_test_features.csv')],\n",
    "                                    stdout=subprocess.PIPE)\n",
    "        testing.wait()\n",
    "        file = open(os.path.join(DATA_PATH, 'tmp/time.txt'))\n",
    "        st = file.readline()\n",
    "        time = float(st)\n",
    "        pred = pd.read_csv(os.path.join(DATA_PATH, 'tmp/model_pred.csv'))\n",
    "        accuracy = scoring.rejection90(data.label.values, pred.prediction.values, data.weight.values)\n",
    "    elif boosting == 'CEGB':\n",
    "        testing = subprocess.Popen(['cpp/cegb_eval',\n",
    "                                    '-model', os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)),\n",
    "                                    '-output', os.path.join(DATA_PATH, 'tmp/model_pred.csv'),\n",
    "                                    '-time', os.path.join(DATA_PATH, 'tmp/time.txt'),\n",
    "                                    '-input', os.path.join(DATA_PATH, 'transformed_test_features.csv'),],\n",
    "                                    stdout=subprocess.PIPE)\n",
    "        testing.wait()\n",
    "        file = open(os.path.join(DATA_PATH, 'tmp/time.txt'))\n",
    "        st = file.readline()\n",
    "        time = float(st)\n",
    "        pred = pd.read_csv(os.path.join(DATA_PATH, 'tmp/model_pred.csv'))\n",
    "        accuracy = scoring.rejection90(data.label.values, pred.prediction.values, data.weight.values)\n",
    "    elif boosting == 'AdaptiveCassifier':\n",
    "        testing = subprocess.Popen(['cpp/gate_eval',\n",
    "                                    '-first', os.path.join(SAVED_MODELS_PATH, create_path('AdaptFirst', parameters['first'])),\n",
    "                                    '-second', os.path.join(SAVED_MODELS_PATH, create_path('AdaptSecond', parameters['second'])),\n",
    "                                    '-gate', os.path.join(SAVED_MODELS_PATH, create_path('AdaptGate', parameters['second'])),\n",
    "                                    '-threshold', str(parameters['threshold']),\n",
    "                                    '-output', os.path.join(DATA_PATH, 'tmp/model_pred.csv'),\n",
    "                                    '-time', os.path.join(DATA_PATH, 'tmp/time.txt'),\n",
    "                                    '-input', os.path.join(DATA_PATH, 'transformed_test_features.csv'),],\n",
    "                                    stdout=subprocess.PIPE)\n",
    "        testing.wait()\n",
    "        file = open(os.path.join(DATA_PATH, 'tmp/time.txt'))\n",
    "        st = file.readline()\n",
    "        time = float(st)\n",
    "        pred = pd.read_csv(os.path.join(DATA_PATH, 'tmp/model_pred.csv'))\n",
    "        accuracy = scoring.rejection90(data.label.values, pred.prediction.values, data.weight.values)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")\n",
    "    return accuracy, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, model, boosting):\n",
    "    if boosting == 'Baseline' or boosting == 'CatBoostClassifier':\n",
    "        return model.predict(data.loc[:, SIMPLE_FEATURE_COLUMNS].values,\n",
    "                             prediction_type=\"RawFormulaVal\").astype(np.float32)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_opt_lr(train_data, test_data, parameters, boosting):\n",
    "    if boosting == 'CatBoostClassifier' or boosting == 'Baseline':\n",
    "        best_model = train_model(train_data, {'learning_rate':None, **parameters}, boosting)\n",
    "        return best_model\n",
    "    elif boosting == 'CEGB':\n",
    "        data = lgb.Dataset(train_data.loc[:, SIMPLE_FEATURE_COLUMNS],\n",
    "                           train_data.label,\n",
    "                           weight=train_data.weight,\n",
    "                           free_raw_data=False)\n",
    "        return train_model(data, parameters, boosting)\n",
    "    elif boosting == 'AdaptiveCassifier':\n",
    "        return train_model(train_data, parameters, boosting)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(boosting, parameters):\n",
    "    filename = [boosting]\n",
    "    for key, value in sorted(parameters.items()):\n",
    "        if key != 'learning_rate':\n",
    "            filename.append(str(key))\n",
    "            filename.append(str(value))\n",
    "    return '_'.join(filename).replace('.', '') + '.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, parameters, boosting):\n",
    "    if boosting == 'CatBoostClassifier':\n",
    "        model.save_model(os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)))\n",
    "    elif boosting == 'CEGB':\n",
    "        model.save_model(os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)))\n",
    "    elif boosting == 'AdaptiveCassifier':\n",
    "        model.first_clf.save_model(os.path.join(SAVED_MODELS_PATH, create_path('AdaptFirst', parameters['first'])))\n",
    "        model.second_clf.save_model(os.path.join(SAVED_MODELS_PATH, create_path('AdaptSecond', parameters['second'])))\n",
    "        model.gate_clf.save_model(os.path.join(SAVED_MODELS_PATH, create_path('AdaptGate', parameters['second'])))\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(parameters, boosting):\n",
    "    if boosting == 'CatBoostClassifier':\n",
    "        return catboost.CatBoostClassifier().load_model(os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)))\n",
    "    elif boosting == 'CEGB':\n",
    "        return lgb.Booster(model_file=os.path.join(SAVED_MODELS_PATH, create_path(boosting, parameters)))\n",
    "    elif boosting == 'AdaptiveCassifier':\n",
    "        first_clf = lgb.Booster(model_file=os.path.join(SAVED_MODELS_PATH, create_path('AdaptFirst', parameters['first'])))\n",
    "        second_clf = lgb.Booster(model_file=os.path.join(SAVED_MODELS_PATH, create_path('AdaptSecond', parameters['second'])))\n",
    "        gate_clf = lgb.Booster(model_file=os.path.join(SAVED_MODELS_PATH, create_path('AdaptGate', parameters['second'])))\n",
    "        return GatedClassifier(parameters['first'], parameters['second'], prob_full=parameters['threshold'],\n",
    "                               first_clf=first_clf, second_clf=second_clf, gate_clf=gate_clf)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_PATH, 'transformed_train_1.csv.gz'))\n",
    "train_lr_data = pd.read_csv(os.path.join(DATA_PATH, 'lr_train.csv.gz'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'transformed_test.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ncl[0]</th>\n",
       "      <th>ncl[1]</th>\n",
       "      <th>ncl[2]</th>\n",
       "      <th>ncl[3]</th>\n",
       "      <th>avg_cs[0]</th>\n",
       "      <th>avg_cs[1]</th>\n",
       "      <th>avg_cs[2]</th>\n",
       "      <th>avg_cs[3]</th>\n",
       "      <th>MatchedHit_TYPE[0]</th>\n",
       "      <th>...</th>\n",
       "      <th>Mextra_DX2[2]</th>\n",
       "      <th>Mextra_DX2[3]</th>\n",
       "      <th>P</th>\n",
       "      <th>PT</th>\n",
       "      <th>sWeight</th>\n",
       "      <th>particle_type</th>\n",
       "      <th>label</th>\n",
       "      <th>kinWeight</th>\n",
       "      <th>weight</th>\n",
       "      <th>sWeight_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8465129</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>3.267442</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.935484</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18547.84200</td>\n",
       "      <td>38555.06000</td>\n",
       "      <td>4488.438145</td>\n",
       "      <td>852.788579</td>\n",
       "      <td>1.231923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.518072</td>\n",
       "      <td>36.850488</td>\n",
       "      <td>0.688562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6710400</td>\n",
       "      <td>87</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>2.678161</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>673.32550</td>\n",
       "      <td>1269.51670</td>\n",
       "      <td>22857.056164</td>\n",
       "      <td>1424.404780</td>\n",
       "      <td>1.218910</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.856460</td>\n",
       "      <td>1.524785</td>\n",
       "      <td>0.821340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8745219</td>\n",
       "      <td>104</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>2.663461</td>\n",
       "      <td>1.914286</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>296.52673</td>\n",
       "      <td>560.07983</td>\n",
       "      <td>33985.939115</td>\n",
       "      <td>874.355152</td>\n",
       "      <td>0.900387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.181888</td>\n",
       "      <td>13.288713</td>\n",
       "      <td>0.249873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6940565</td>\n",
       "      <td>78</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>1.956522</td>\n",
       "      <td>1.409091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>112.60395</td>\n",
       "      <td>213.23407</td>\n",
       "      <td>52486.563851</td>\n",
       "      <td>5227.835837</td>\n",
       "      <td>0.957750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.590642</td>\n",
       "      <td>0.863547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8806331</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2.747573</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>159.62965</td>\n",
       "      <td>305.14374</td>\n",
       "      <td>44804.467467</td>\n",
       "      <td>6284.289883</td>\n",
       "      <td>1.047418</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.519684</td>\n",
       "      <td>7.410785</td>\n",
       "      <td>0.251046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ncl[0]  ncl[1]  ncl[2]  ncl[3]  avg_cs[0]  avg_cs[1]  \\\n",
       "0     8465129      86      12      31      14   3.267442   2.750000   \n",
       "1     6710400      87      36      14      20   2.678161   3.250000   \n",
       "2     8745219     104      35      18      22   2.663461   1.914286   \n",
       "3     6940565      78      23      22      15   2.653846   1.956522   \n",
       "4     8806331     103      15      12      10   2.747573   2.066667   \n",
       "\n",
       "   avg_cs[2]  avg_cs[3]  MatchedHit_TYPE[0]  ...  Mextra_DX2[2]  \\\n",
       "0   1.935484   1.285714                   2  ...    18547.84200   \n",
       "1   1.214286   1.350000                   2  ...      673.32550   \n",
       "2   1.722222   1.318182                   2  ...      296.52673   \n",
       "3   1.409091   1.000000                   2  ...      112.60395   \n",
       "4   1.833333   1.100000                   2  ...      159.62965   \n",
       "\n",
       "   Mextra_DX2[3]             P           PT   sWeight  particle_type  label  \\\n",
       "0    38555.06000   4488.438145   852.788579  1.231923              0      0   \n",
       "1     1269.51670  22857.056164  1424.404780  1.218910              1      1   \n",
       "2      560.07983  33985.939115   874.355152  0.900387              0      0   \n",
       "3      213.23407  52486.563851  5227.835837  0.957750              1      1   \n",
       "4      305.14374  44804.467467  6284.289883  1.047418              2      0   \n",
       "\n",
       "   kinWeight     weight  sWeight_transformed  \n",
       "0  53.518072  36.850488             0.688562  \n",
       "1   1.856460   1.524785             0.821340  \n",
       "2  53.181888  13.288713             0.249873  \n",
       "3   3.000000   2.590642             0.863547  \n",
       "4  29.519684   7.410785             0.251046  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = train.append(train_lr_data)\n",
    "lgb_train = lgb.Dataset(full_train.loc[:, SIMPLE_FEATURE_COLUMNS],\n",
    "                        full_train.label,\n",
    "                        weight=full_train.weight,\n",
    "                        free_raw_data=False)\n",
    "lgb_test = lgb.Dataset(os.path.join(DATA_PATH, 'transformed_test.bin'),\n",
    "                       reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN or not os.path.exists(os.path.join(SAVED_MODELS_PATH, 'baseline.cbm')):\n",
    "    baseline = find_opt_lr(train_lr_data, test, {}, 'Baseline')\n",
    "    baseline.fit(train.loc[:, SIMPLE_FEATURE_COLUMNS].values,\n",
    "                 train.label.values,\n",
    "                 sample_weight=train.weight.values)\n",
    "    if SAVE or not os.path.exists(os.path.join(SAVED_MODELS_PATH, 'baseline.cbm')):\n",
    "        baseline.save_model(os.path.join(SAVED_MODELS_PATH, 'baseline.cbm'))\n",
    "else:\n",
    "    baseline = catboost.CatBoostClassifier().load_model(os.path.join(SAVED_MODELS_PATH, 'baseline.cbm'))\n",
    "\n",
    "\n",
    "baseline_accuracy, baseline_time = evaluate(test, {}, 'Baseline', baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for models\n",
    "boosting_parameters = {\n",
    "    'AdaptiveCassifier': {\n",
    "        'first_tree': [40, 50, 60, 70, 80],\n",
    "        'second_tree': [7, 9, 11, 13, 15],\n",
    "        'threshold': [0.2, 0.35, 0.5, 0.65, 0.8]\n",
    "    },\n",
    "    'CatBoostClassifier': {\n",
    "        'tree_count': [*range(10, 600, 25)],\n",
    "    },\n",
    "    'CEGB': {\n",
    "        'tree_count': [*range(10, 101, 10)],\n",
    "        'num_leaves': [*range(10, 51, 5)]\n",
    "    },\n",
    "}\n",
    "boosting_list = ['AdaptiveCassifier', 'CatBoostClassifier', 'CEGB',]\n",
    "boosting_res = {}\n",
    "for boosting in boosting_list:\n",
    "    boosting_res[boosting] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Grid Search with given parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetParameters(object):\n",
    "    def __init__(self, parameters, lengths=None):\n",
    "        self.parameters = parameters\n",
    "        if lengths is None:\n",
    "            self.lengths = []\n",
    "            for ls in parameters.values():\n",
    "                self.lengths.append(len(ls) - 1)\n",
    "        else:\n",
    "            assert(len(lengths) == len(self.parameters))\n",
    "            self.lengths = lengths\n",
    "        self.is_generator = []\n",
    "        for value in parameters.values():\n",
    "            if hasattr(value, '__call__'):\n",
    "                self.is_generator.append(True)\n",
    "            else:\n",
    "                self.is_generator.append(False)\n",
    "        self.current = None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def get_by_index(self, index):\n",
    "        parameters = {}\n",
    "        for it, parameter in enumerate(self.parameters.items()):\n",
    "            if self.is_generator[it]:\n",
    "                parameters[parameter[0]] = parameter[1]()\n",
    "            else:\n",
    "                parameters[parameter[0]] = parameter[1][self.current[it]]\n",
    "        return parameters\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current is None:\n",
    "            self.current = [0] * len(self.lengths)\n",
    "            return self.get_by_index(self.current)\n",
    "        else:\n",
    "            for it in reversed(range(len(self.lengths))):\n",
    "                if self.current[it] == self.lengths[it]:\n",
    "                    self.current[it] = 0\n",
    "                else:\n",
    "                    self.current[it] += 1\n",
    "                    return self.get_by_index(self.current)\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ec601cb7ef10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mcurrent_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_clf'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfirst_clf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mboosting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CEGB'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'AdaptiveCassifier'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_opt_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_opt_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-18d432fa36c4>\u001b[0m in \u001b[0;36mfind_opt_lr\u001b[0;34m(train_data, test_data, parameters, boosting)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mboosting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AdaptiveCassifier'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown boosting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-917c19c8d1d1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data, parameters, boosting, model)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mparams_second\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_iterations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'second'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tree_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGatedClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown boosting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f571efacb134>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_second\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_second\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mscore_second_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIMPLE_FEATURE_COLUMNS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/yukondratov/env/lib/python3.6/site-packages/lightgbm-0.2-py3.6.egg/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m             \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/yukondratov/env/lib/python3.6/site-packages/lightgbm-0.2-py3.6.egg/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_predict\u001b[0;34m(self, data_idx)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0mn_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;34m\"\"\"avoid to predict many time in one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for boosting, parameters in boosting_parameters.items():\n",
    "    for current_parameters in GetParameters(parameters):\n",
    "        if boosting == 'AdaptiveCassifier':\n",
    "            current_parameters = {\n",
    "                'first': {\n",
    "                    'tree_count': current_parameters['first_tree']\n",
    "                },\n",
    "                'second': {\n",
    "                    'first_trees': 'tree_count': current_parameters['first_tree'],\n",
    "                    'tree_count': current_parameters['second_tree'],\n",
    "                    'threshold': current_parameters['threshold']\n",
    "                },\n",
    "                'threshold': current_parameters['threshold'],\n",
    "            }\n",
    "        if TRAIN or not os.path.exists(os.path.join(SAVED_MODELS_PATH,\n",
    "                                                    create_path(boosting, current_parameters))):\n",
    "            if (boosting == 'AdaptiveCassifier' and\n",
    "                    os.path.exists(os.path.join(SAVED_MODELS_PATH, create_path('AdoptFirst', current_parameters['first'])))):\n",
    "                first_clf = lgb.Booster(model_file=os.path.join(SAVED_MODELS_PATH, create_path('AdaptFirst', current_parameters['first'])))\n",
    "                current_parameters['first_clf': first_clf]\n",
    "            if boosting == 'CEGB' or 'AdaptiveCassifier':\n",
    "                model = find_opt_lr(full_train, test, current_parameters, boosting)\n",
    "            else:\n",
    "                model = find_opt_lr(train_lr_data, test, current_parameters, boosting)\n",
    "                model = train_model(data=train, boosting=boosting, model=model)\n",
    "            if (SAVE or\n",
    "                    boosting != 'AdaptiveCassifier' and not os.path.exists(os.path.join(SAVED_MODELS_PATH,\n",
    "                    create_path(boosting, current_parameters))) or\n",
    "                    boosting == 'AdaptiveCassifier' and not os.path.exists(os.path.join(SAVED_MODELS_PATH,\n",
    "                    create_path('AdaptSecond', current_parameters['second'])))):\n",
    "                save_model(model, current_parameters, boosting)\n",
    "        else:\n",
    "            model = load_model(current_parameters, boosting)\n",
    "        accuracy, time = evaluate(test, current_parameters, boosting, model)\n",
    "        if 'first_clf' in current_parameters:\n",
    "            current_parameters.pop('first_clf')\n",
    "        result = {**current_parameters}\n",
    "        result['accuracy'] = accuracy\n",
    "        result['time'] = time\n",
    "        boosting_res[boosting].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_colours = ['b', 'g', 'r', 'y', 'k', 'c', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[baseline_time * 0.02, baseline_time] = [0.0532846, 2.66423]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ad17a1108390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmin_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmax_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_colours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboosting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/yukondratov/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \"\"\"\n\u001b[1;32m   2617\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2618\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/yukondratov/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[baseline_time * 0.02, baseline_time] =\", [baseline_time * 0.02, baseline_time])\n",
    "min_y = 1\n",
    "max_y = 0\n",
    "for it, boosting in enumerate(boosting_parameters.keys()):\n",
    "    results = {}\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    for res in boosting_res[boosting]:\n",
    "        results[res['time']] = res['accuracy']\n",
    "    for time in sorted(results.keys()):\n",
    "        times.append(time)\n",
    "        accuracies.append(results[time])\n",
    "    min_y = min(np.min(accuracies), min_y)\n",
    "    max_y = max(np.max(accuracies), max_y)\n",
    "    plt.plot(times, accuracies, plt_colours[it], label=boosting)\n",
    "plt.xlim([baseline_time * 0.02, baseline_time])\n",
    "plt.ylim([min_y - 0.01, max_y + 0.01])\n",
    "plt.xlabel('Time spent on test data, sec')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score/Time graph for all models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
